{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data_files/All_dup_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import ujson as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the files storing the <q_id, list of <4 scores with each contender>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_files/All_dup_scores/jac_dup_score_details_100_test.json\",'r') as fd:\n",
    "    df=json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.keys())[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verifying there are 100 keys, one per each question in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(df.keys())==100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['440482']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_id_mapping_to_param_pos={\n",
    "    0:\"title_score\",\n",
    "    1:\"body_score\",\n",
    "    2:\"topic_score\",\n",
    "    3:\"tag_score\",\n",
    "    4:\"jaccard_sim\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params_models.json\",'r') as fd:\n",
    "    params_dict=json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PARAMS=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for curr_elem in params_dict:\n",
    "    # see if number of coeffs less than MAX_PARAMS and pad with zeroes to the right\n",
    "    while(len(curr_elem['params_arr'])<MAX_PARAMS):\n",
    "        curr_elem['params_arr'].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_test_id=0\n",
    "for curr_test_q_id, curr_elem in df.items():\n",
    "    # iterate through each candidate\n",
    "    print(\"curr_test id is \", curr_test_id, len(curr_elem['scores']))\n",
    "    curr_test_id+=1\n",
    "    for curr_candidate_q in curr_elem['scores']:\n",
    "        curr_candidate_q['cm_s']=[]\n",
    "        # store candidates score for each model\n",
    "        # iterate through each model\n",
    "        for curr_model in params_dict:\n",
    "            curr_score=0\n",
    "            for param_idx, param_val in enumerate(curr_model['params_arr']):\n",
    "                concerned_feature=coeff_id_mapping_to_param_pos[param_idx]\n",
    "                curr_score+=param_val * curr_candidate_q[concerned_feature]\n",
    "                #print(\"mult : \",param_val , curr_candidate_q[concerned_feature])\n",
    "            curr_candidate_q['cm_s'].append(curr_score)\n",
    "        #print(\"candidate details is \", curr_candidate_q)\n",
    "        #break\n",
    "    #break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.4 * 0) + (0.5 *  0.1500468969841066) + (0.13737961695900214 * 0.006948283464124975) + (0.19916776750438459 * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_files/test_set_q_candidate_model_scores.json\",'w') as fd:\n",
    "    json.dump(df, fd, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
