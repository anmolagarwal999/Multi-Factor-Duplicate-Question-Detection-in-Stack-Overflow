{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from preprocessing import Preprocess as preprocess_class\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_object=preprocess_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide the input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_FILE_PATH=\"data_files/pp_nov_28/result/\"\n",
    "PREFIX_OUTPUT_FILE_PATH=\"data_files/cleaned_pp_nov_28_all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_file_idx=0\n",
    "ub_file_idx=102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To clean self-closing tags and both closing tags from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/11229866\n",
    "self_contained_ref_regex=r\"<[^>]*>\"\n",
    "self_contained_ref_pattern=re.compile(self_contained_ref_regex)\n",
    "\n",
    "def clean_tags_prevent_content(curr_text):\n",
    "    curr_text=self_contained_ref_pattern.sub(\" \",curr_text)\n",
    "    return curr_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_cases=[\"< Hello> There </Hello>\",\n",
    "            \"billy butcher\",\n",
    "              \"<Doncaster/>\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tc is  < Hello> There </Hello>\n",
      "Output  is    There  \n",
      "**********\n",
      "tc is  billy butcher\n",
      "Output  is  billy butcher\n",
      "**********\n",
      "tc is  <Doncaster/>\n",
      "Output  is   \n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for curr_tc in tc_cases:\n",
    "    print(\"tc is \",curr_tc)\n",
    "    print(\"Output  is \",clean_tags_prevent_content(curr_tc) )\n",
    "    print(\"**********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning newlines and tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_newline_stuff(curr_text):\n",
    "    curr_text=curr_text.replace(\"\\n\",\"\")\n",
    "    curr_text=curr_text.replace(\"\\t\",\"\")\n",
    "    return curr_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching question tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tags_list(tag_text):\n",
    "    arr=tag_text.split(\">\")\n",
    "    arr=list(filter(lambda x:x!=\"\",arr))\n",
    "    arr=[x[1:] for x in arr]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_cases=['<performance><unix><awk><aix>',\n",
    "            '<c#><exception><error-handling>',\n",
    "              \"<Doncaster>\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tc is  <performance><unix><awk><aix>\n",
      "Output  is  ['performance', 'unix', 'awk', 'aix']\n",
      "**********\n",
      "tc is  <c#><exception><error-handling>\n",
      "Output  is  ['c#', 'exception', 'error-handling']\n",
      "**********\n",
      "tc is  <Doncaster>\n",
      "Output  is  ['Doncaster']\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for curr_tc in tc_cases:\n",
    "    print(\"tc is \",curr_tc)\n",
    "    print(\"Output  is \",fetch_tags_list(curr_tc) )\n",
    "    print(\"**********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all variations of the word \"DUPLICATE\" from title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd [  duplicaTe] fghi j \n",
      "['[  duplicaTe]']\n",
      "Rem part is  abcd   fghi j \n",
      "##########\n",
      "[   duplicaTE       ]\n",
      "['[   duplicaTE       ]']\n",
      "Rem part is   \n",
      "##########\n",
      "[duplicaTE]\n",
      "['[duplicaTE]']\n",
      "Rem part is   \n",
      "##########\n",
      "abcdef [duplicaTE] dupl sis os\n",
      "['[duplicaTE]']\n",
      "Rem part is  abcdef   dupl sis os\n",
      "##########\n",
      "skjsis9\n",
      "[]\n",
      "Rem part is  skjsis9\n",
      "##########\n",
      "Is null harmful? [Duplicate]\n",
      "['[Duplicate]']\n",
      "Rem part is  Is null harmful?  \n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "test_dup_reg=re.compile(r\"\\[\\s*duplicate\\s*\\]\", re.IGNORECASE)\n",
    "testing_dup_title_string=[\"abcd [  duplicaTe] fghi j \"\n",
    "                            ,\"[   duplicaTE       ]\"\n",
    "                             ,\"[duplicaTE]\"\n",
    "                          ,\"abcdef [duplicaTE] dupl sis os\"        ,\n",
    "                          \"skjsis9\",\n",
    "                          \"Is null harmful? [Duplicate]\"\n",
    "                         ]\n",
    "\n",
    "#dup_regex = re.compile(\"duplicate\", re.IGNORECASE)\n",
    "def rem_dup(text):\n",
    "    return test_dup_reg.sub(\" \", text)\n",
    "\n",
    "for curr_tc in testing_dup_title_string:\n",
    "    matches=test_dup_reg.findall(curr_tc)\n",
    "    print(curr_tc)\n",
    "    print(matches)\n",
    "    print(\"Rem part is \", rem_dup(curr_tc))\n",
    "    print(\"##########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing \"code\"/blockquote tag and the content inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_paired_refs_regex=r\"<code((.|\\n)*?)<\\/code>\"\n",
    "code_paired_refs_pattern=re.compile(code_paired_refs_regex)\n",
    "def rem_code(text):\n",
    "    return code_paired_refs_pattern.sub(\" \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test code block removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc=[\"<p>I'm new to C# and I want to use a track-bar to change a form's opacity\\\n",
    "            .</p>\\n\\n<p>This is my code:</p>\\n\\n<pre>\\\n",
    "        <code>decimal trans = trackBar1.Value / 5000;\\nthis.Opacity = trans;\\n</code>\\\n",
    "                </pre>\\n\\n<p>When I try to build it, I get this error:</p>\\n\\n<blockquote>\\n  <p>Cannot implicitly convert type 'decimal' to 'double'</p>\\n</blockquote>\\n\\n<p>I tried making\\ <code>trans</code> \\\n",
    "    a double, but then the control doesn't work. This code worked fine for me in VB.NET. </p>\\n\\n<p>What do I need to do differently?</p>\\n\",\n",
    "    \"<code>decimal trans = trackBar1.Value / 5000;\\nthis.Opacity = trans;\\n</code>\",\n",
    "    \"Homelander <code> Hi Hi </code> Bi <code>Hello there</code>\"\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>I'm new to C# and I want to use a track-bar to change a form's opacity            .</p>\n",
      "\n",
      "<p>This is my code:</p>\n",
      "\n",
      "<pre>        <code>decimal trans = trackBar1.Value / 5000;\n",
      "this.Opacity = trans;\n",
      "</code>                </pre>\n",
      "\n",
      "<p>When I try to build it, I get this error:</p>\n",
      "\n",
      "<blockquote>\n",
      "  <p>Cannot implicitly convert type 'decimal' to 'double'</p>\n",
      "</blockquote>\n",
      "\n",
      "<p>I tried making\\ <code>trans</code>     a double, but then the control doesn't work. This code worked fine for me in VB.NET. </p>\n",
      "\n",
      "<p>What do I need to do differently?</p>\n",
      "\n",
      ":::::::::\n",
      "<p>I'm new to C# and I want to use a track-bar to change a form's opacity            .</p>\n",
      "\n",
      "<p>This is my code:</p>\n",
      "\n",
      "<pre>                         </pre>\n",
      "\n",
      "<p>When I try to build it, I get this error:</p>\n",
      "\n",
      "<blockquote>\n",
      "  <p>Cannot implicitly convert type 'decimal' to 'double'</p>\n",
      "</blockquote>\n",
      "\n",
      "<p>I tried making\\       a double, but then the control doesn't work. This code worked fine for me in VB.NET. </p>\n",
      "\n",
      "<p>What do I need to do differently?</p>\n",
      "\n",
      "##################################\n",
      "<code>decimal trans = trackBar1.Value / 5000;\n",
      "this.Opacity = trans;\n",
      "</code>\n",
      ":::::::::\n",
      " \n",
      "##################################\n",
      "Homelander <code> Hi Hi </code> Bi <code>Hello there</code>\n",
      ":::::::::\n",
      "Homelander   Bi  \n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "for curr_tc in tc:\n",
    "    print(curr_tc)\n",
    "    print(\":::::::::\")\n",
    "    print(rem_code(curr_tc))\n",
    "    print(\"##################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = re.compile(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\")\n",
    "def fetch_urls(curr_str):\n",
    "    url_matches = url_regex.findall(curr_str)      \n",
    "    return [x[0] for x in url_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockquote_paired_refs_regex=r\"<blockquote((.|\\n)*?)<\\/blockquote>\"\n",
    "blockquote_paired_refs_pattern=re.compile(blockquote_paired_refs_regex)\n",
    "def rem_blockquote(text):\n",
    "    #print(\"num is : \",len(fetch_urls(text)))\n",
    "    if (\"blockquote\" in text)  and (len(fetch_urls(text))>0):\n",
    "        return blockquote_paired_refs_pattern.sub(\" \", text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<blockquote>\n",
      "  <h2>Duplicate</h2>\n",
      "  \n",
      "  <p><a href=\"http://stackoverflow.com/questions/403539/what-are-extension-methods\">What are Extension Methods?</a><br />\n",
      "  <a href=\"http://stackoverflow.com/questions/403619/usage-of-extension-methods\">Usage of Extension Methods</a><br />\n",
      "  <a href=\"http://stackoverflow.com/questions/487904/what-advantages-of-extension-methods-have-you-found\">What Advantages of Extension Methods have you found?</a>  </p>\n",
      "</blockquote>\n",
      "\n",
      ":::::::::\n",
      "ans is :   \n",
      "\n",
      "##################################\n",
      "<blockquote>\n",
      "  <p>Cannot implicitly convert type 'decimal' to 'double'</p>\n",
      "</blockquote>\n",
      ":::::::::\n",
      "ans is :  <blockquote>\n",
      "  <p>Cannot implicitly convert type 'decimal' to 'double'</p>\n",
      "</blockquote>\n",
      "##################################\n",
      "<blockquote>\n",
      "  <p>Duplicate:\n",
      "  <a href=\"http://stackoverflow.com/questions/163434/are-nulls-in-a-relational-database-okay\">http://stackoverflow.com/questions/163434/are-nulls-in-a-relational-database-okay</a></p>\n",
      "</blockquote>\n",
      "\n",
      ":::::::::\n",
      "ans is :   \n",
      "\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "tc=['<blockquote>\\n  <h2>Duplicate</h2>\\n  \\n  <p><a href=\\\"http://stackoverflow.com/questions/403539/what-are-extension-methods\\\">What are Extension Methods?</a><br />\\n  <a href=\\\"http://stackoverflow.com/questions/403619/usage-of-extension-methods\\\">Usage of Extension Methods</a><br />\\n  <a href=\\\"http://stackoverflow.com/questions/487904/what-advantages-of-extension-methods-have-you-found\\\">What Advantages of Extension Methods have you found?</a>  </p>\\n</blockquote>\\n',\n",
    "   \"<blockquote>\\n  <p>Cannot implicitly convert type 'decimal' to 'double'</p>\\n</blockquote>\",\n",
    "   \"<blockquote>\\n  <p>Duplicate:\\n  <a href=\\\"http://stackoverflow.com/questions/163434/are-nulls-in-a-relational-database-okay\\\">http://stackoverflow.com/questions/163434/are-nulls-in-a-relational-database-okay</a></p>\\n</blockquote>\\n\"]\n",
    "for curr_tc in tc:\n",
    "    print(curr_tc)\n",
    "    print(\":::::::::\")\n",
    "    print(\"ans is : \",rem_blockquote(curr_tc))\n",
    "    print(\"##################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_question_satisfying_a_condition(fn):\n",
    "    ans=None\n",
    "    for file_id in range(lb_file_idx, ub_file_idx+1):\n",
    "        if ans!=None:\n",
    "            break\n",
    "        print(\"Starting file with id: \", file_id)\n",
    "        with open(PREFIX_FILE_PATH+f\"/post_{file_id}.json\",'r') as fd:\n",
    "            df=json.load(fd)\n",
    "        new_df=dict()\n",
    "        for curr_key, curr_val in df.items():\n",
    "            # we do not want to process answers\n",
    "            if curr_val[\"PostTypeId\"]!=\"1\":\n",
    "                continue\n",
    "            if fn(curr_val):\n",
    "                ans=deepcopy(curr_val)\n",
    "                print(\"Found\")\n",
    "                break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_tag_in_body(curr_obj):\n",
    "    all_matches=code_paired_refs_pattern.findall(curr_obj['Body'])\n",
    "    return len(all_matches)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockquote_tag_in_body(curr_obj):\n",
    "    all_matches=blockquote_paired_refs_pattern.findall(curr_obj['Body'])\n",
    "    return len(all_matches)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_question_id_object(q_id):\n",
    "    ans=None\n",
    "    assert(type(q_id)==str)\n",
    "    for file_id in range(lb_file_idx, ub_file_idx+1):\n",
    "        if ans!=None:\n",
    "            break\n",
    "        print(\"Starting file with id: \", file_id)\n",
    "        with open(PREFIX_FILE_PATH+f\"/post_{file_id}.json\",'r') as fd:\n",
    "            df=json.load(fd)\n",
    "        new_df=dict()\n",
    "        for curr_key, curr_val in df.items():\n",
    "            # we do not want to process answers\n",
    "            if curr_val[\"PostTypeId\"]!=\"1\":\n",
    "                continue\n",
    "            if curr_val['Id']==q_id:\n",
    "                ans=deepcopy(curr_val)\n",
    "                print(\"Found\")\n",
    "                break\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_question_satisfying_a_condition(code_tag_in_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_question_satisfying_a_condition(blockquote_tag_in_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_question_id_object(\"777711\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just investigate the PostTypeIDs present (DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_post_types():\n",
    "    for curr_id, curr_val in df.items():\n",
    "        if curr_val['PostTypeId']!='1':\n",
    "            print(curr_val['PostTypeId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, first find a duplicate and verify Gurkirat claim of just 2 duplicates using the paper's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dups_in_title():\n",
    "    lb_file_idx=0\n",
    "    ub_file_idx=102\n",
    "\n",
    "    potential_dups_yet=0\n",
    "\n",
    "    for file_id in range(lb_file_idx, ub_file_idx+1):\n",
    "        print(\"Starting file with id: \", file_id)\n",
    "        with open(PREFIX_FILE_PATH+f\"/post_{file_id}.json\",'r') as fd:\n",
    "            df=json.load(fd)\n",
    "        new_df=dict()\n",
    "        for curr_key, curr_val in df.items():\n",
    "            # we do not want to process answers\n",
    "            if curr_val[\"PostTypeId\"]!=\"1\":\n",
    "                continue\n",
    "            matches=test_reg.findall(curr_val['Title'])\n",
    "            if len(matches)>0:\n",
    "                print(curr_key)\n",
    "                print(curr_val)\n",
    "                print(\"$$$$$$$$$$$$$$$$$$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_dups_in_title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_post(post_obj):\n",
    "    new_val=deepcopy(post_obj)\n",
    "    new_val['cleaned_body']=rem_blockquote(new_val['Body'])\n",
    "    #print(\"After rem is \",new_val['cleaned_body'] )\n",
    "    new_val['cleaned_body']=rem_code(new_val['cleaned_body'])\n",
    "    new_val['cleaned_body']=clean_tags_prevent_content(new_val['cleaned_body'])\n",
    "    new_val['cleaned_body']=clean_newline_stuff(new_val['cleaned_body'])\n",
    "\n",
    "    new_val['cleaned_title']=rem_dup(new_val['Title'])\n",
    "\n",
    "    new_val['body_vec']=preprocess_object.parse_string(new_val['cleaned_body'])\n",
    "    new_val['title_vec']=preprocess_object.parse_string(new_val['cleaned_title'])\n",
    "\n",
    "    try:\n",
    "        new_val['tags_list']=fetch_tags_list(new_val['Tags'])\n",
    "    except:\n",
    "        new_val['tags_list']=[]\n",
    "        print(curr_val)\n",
    "        #break\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file with id:  0\n",
      "Found\n",
      "Starting file with id:  0\n",
      "Found\n",
      "Starting file with id:  0\n",
      "Starting file with id:  1\n",
      "Starting file with id:  2\n",
      "Starting file with id:  3\n",
      "Starting file with id:  4\n",
      "Starting file with id:  5\n",
      "Found\n",
      "Starting file with id:  0\n",
      "Starting file with id:  1\n",
      "Starting file with id:  2\n",
      "Starting file with id:  3\n",
      "Starting file with id:  4\n",
      "Starting file with id:  5\n",
      "Found\n"
     ]
    }
   ],
   "source": [
    "test_arr=[fetch_question_satisfying_a_condition(code_tag_in_body),\n",
    "         fetch_question_satisfying_a_condition(blockquote_tag_in_body),\n",
    "          fetch_question_id_object('777711'),\n",
    "          fetch_question_id_object('783926')\n",
    "                                               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans=[]\n",
    "for curr_tc in test_arr:\n",
    "    curr_d=dict()\n",
    "    curr_d['input']=deepcopy(curr_tc)\n",
    "    curr_d['output']=clean_post(curr_tc)\n",
    "    test_ans.append(curr_d)\n",
    "with open(\"sample_of_cleanings.json\",'w') as fd:\n",
    "    json.dump(test_ans, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cnt=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting file with id:  0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "Finished  0\n",
      "-----------\n",
      "Starting file with id:  1\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "Finished  1\n",
      "-----------\n",
      "Starting file with id:  2\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "Finished  2\n",
      "-----------\n",
      "Starting file with id:  3\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "Finished  3\n",
      "-----------\n",
      "Starting file with id:  4\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "Finished  4\n",
      "-----------\n",
      "Starting file with id:  5\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "Finished  5\n",
      "-----------\n",
      "Starting file with id:  6\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "Finished  6\n",
      "-----------\n",
      "Starting file with id:  7\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "Finished  7\n",
      "-----------\n",
      "Starting file with id:  8\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "Finished  8\n",
      "-----------\n",
      "Starting file with id:  9\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "Finished  9\n",
      "-----------\n",
      "Starting file with id:  10\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "Finished  10\n",
      "-----------\n",
      "Starting file with id:  11\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "Finished  11\n",
      "-----------\n",
      "Starting file with id:  12\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n",
      "345000\n",
      "346000\n",
      "347000\n",
      "348000\n",
      "349000\n",
      "350000\n",
      "351000\n",
      "352000\n",
      "353000\n",
      "354000\n",
      "355000\n",
      "356000\n",
      "357000\n",
      "358000\n",
      "359000\n",
      "360000\n",
      "361000\n",
      "362000\n",
      "363000\n",
      "364000\n",
      "365000\n",
      "366000\n",
      "367000\n",
      "368000\n",
      "Finished  12\n",
      "-----------\n",
      "Starting file with id:  13\n",
      "369000\n",
      "370000\n",
      "371000\n",
      "372000\n",
      "373000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-9758a3f9ec9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtot_cnt\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-4d0e2bae1fe5>\u001b[0m in \u001b[0;36mclean_post\u001b[0;34m(post_obj)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnew_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnew_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrem_blockquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(\"After rem is \",new_val['cleaned_body'] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnew_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrem_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_id in range(lb_file_idx, ub_file_idx+1):\n",
    "    print(\"Starting file with id: \", file_id)\n",
    "    with open(PREFIX_FILE_PATH+f\"/post_{file_id}.json\",'r') as fd:\n",
    "        df=json.load(fd)\n",
    "    new_df=dict()\n",
    "    for curr_key, curr_val in df.items():\n",
    "        # we do not want to process answers\n",
    "        if curr_val[\"PostTypeId\"]!=\"1\":\n",
    "            continue\n",
    "        tot_cnt+=1\n",
    "        if tot_cnt%1000==0:\n",
    "            print(tot_cnt)\n",
    "        new_df[curr_key]=clean_post(curr_val)\n",
    "    print(\"Finished \", file_id)\n",
    "    print(\"-----------\")\n",
    "    with open(PREFIX_OUTPUT_FILE_PATH+f\"/post_{file_id}.json\",'w') as fd:\n",
    "        json.dump(new_df, fd, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cnt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
